# NLP: Tokenization & Stopword Removal

# Step 1: Download NLTK resources
import nltk
nltk.download('punkt')
nltk.download('stopwords')

# Step 2: Import libraries
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

# Step 3: Sample text
text = "Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence.
It allows machines to read, understand, and generate human language."

# Step 4: Lowercase and remove punctuation
text_clean = text.lower().translate(str.maketrans('', '', string.punctuation))

# Step 5: Tokenize
tokens = word_tokenize(text_clean)

# Step 6: Remove stopwords
stop_words = set(stopwords.words("english"))
filtered_tokens = [word for word in tokens if word not in stop_words]

# Step 7: Print output
print("Original Tokens:\n", tokens)
print("\nFiltered Tokens (no stopwords):\n", filtered_tokens)

